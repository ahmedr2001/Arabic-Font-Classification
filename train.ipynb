{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import preprocessing\n",
    "import feature_extraction \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from joblib import dump, load  # For model persistence\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder, num_images_per_class=50):\n",
    "    images = {}\n",
    "    for class_name in os.listdir(folder):\n",
    "        class_path = os.path.join(folder, class_name)\n",
    "        # Get a list of all filenames in the class_path directory\n",
    "        all_files = os.listdir(class_path)\n",
    "        # Choose random filenames from the list\n",
    "        random_files = random.sample(all_files, min(num_images_per_class, len(all_files)))\n",
    "        print(class_name)\n",
    "        category_images = []\n",
    "        for filename in random_files:\n",
    "            image_path = os.path.join(class_path, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "            image = preprocessing.preprocess(image)\n",
    "            category_images.append(image)\n",
    "        \n",
    "        images[class_name] = category_images\n",
    "    \n",
    "    return images\n",
    "\n",
    "# Usage example\n",
    "data_dir = \"fonts-dataset\"\n",
    "num_images_per_class = 50\n",
    "classes_dic = {\"IBM Plex Sans Arabic\": 0, \"Lemonada\": 1, \"Marhey\": 2, \"Scheherazade New\": 3}\n",
    "\n",
    "images = load_images_from_folder(data_dir, num_images_per_class)\n",
    "test = load_images_from_folder(data_dir, 10)\n",
    "print(\"Loading data is done ........\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load kmeans centers\n",
    "centers = feature_extraction.kmeans_centers()\n",
    "\n",
    "# Create histograms for each class_name for each image in images\n",
    "X_train = []\n",
    "Y_train = []\n",
    "for class_name, class_images in images.items():\n",
    "    for image in class_images:\n",
    "        X_train.append(feature_extraction.histogram_from_sift(image, centers))\n",
    "        Y_train.append(classes_dic[class_name])\n",
    "\n",
    "# Create histograms for each class_name for each image in test\n",
    "X_test = []\n",
    "Y_test = []\n",
    "for class_name, class_images in test.items():\n",
    "    for image in class_images:\n",
    "        X_test.append(feature_extraction.histogram_from_sift(image, centers))\n",
    "        Y_test.append(classes_dic[class_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[0])\n",
    "\n",
    "# Step 2: Train kNN Model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)  # Example: k=5\n",
    "knn_model.fit(X_train, Y_train)\n",
    "\n",
    "# Step 3: Save Trained Model\n",
    "dump(knn_model, 'models/knn_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Make Predictions\n",
    "predicted_labels = knn_model.predict(X_train)\n",
    "\n",
    "# Step 4: Calculate Accuracy\n",
    "accuracy = np.mean(predicted_labels == Y_train)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Train SVM model\n",
    "svm_model = SVC(kernel='rbf')  # You can adjust the kernel as needed\n",
    "svm_model.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions on test data\n",
    "svm_predictions = svm_model.predict(X_train)\n",
    "\n",
    "# Calculate accuracy\n",
    "svm_accuracy = accuracy_score(Y_train, svm_predictions)\n",
    "print(\"SVM Accuracy:\", svm_accuracy)\n",
    "dump(svm_model, 'models/svm_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Train Naive Bayes model\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions on test data\n",
    "nb_predictions = nb_model.predict(X_train)\n",
    "\n",
    "# Calculate accuracy\n",
    "nb_accuracy = accuracy_score(Y_train, nb_predictions)\n",
    "print(\"Naive Bayes Accuracy:\", nb_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shallow neural network classifier (2 hidden layers)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# 2 hidden layers with 100 and 50 neurons\n",
    "nn_model = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000)\n",
    "nn_model.fit(X_train, Y_train)\n",
    "\n",
    "# Save NN Model\n",
    "dump(nn_model, 'models/nn_model.pkl')\n",
    "\n",
    "# Load NN Model\n",
    "nn_model = load('models/nn_model.pkl')\n",
    "\n",
    "# Predict Test Data\n",
    "Y_pred = nn_model.predict(X_train)\n",
    "\n",
    "# Calculate Accuracy\n",
    "accuracy = accuracy_score(Y_train, Y_pred)\n",
    "print(\"Accuracy: %\", accuracy * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
